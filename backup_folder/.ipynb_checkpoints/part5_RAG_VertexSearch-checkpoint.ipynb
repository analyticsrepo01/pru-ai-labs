{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f645c1c4-23bf-42a9-a5a7-e21096afce25",
   "metadata": {},
   "source": [
    "### Configuration and Datasetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4fb700-fb8f-4fba-9bba-4f7ee1ef232b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-discoveryengine in /home/jupyter/.local/lib/python3.10/site-packages (0.11.7)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (2.17.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-cloud-discoveryengine) (2.23.4)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-cloud-discoveryengine) (1.22.3)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-cloud-discoveryengine) (3.20.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (1.61.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (1.59.2)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-discoveryengine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248e052c-873a-473e-a72d-9500cc2d6633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade google-cloud-discoveryengine -q --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cccd71a-b5bd-4a6a-b9ac-e56eb0f69e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO(developer): Uncomment these variables before running the sample.\n",
    "# location = \"YOUR_LOCATION\" # Values: \"global\"\n",
    "# data_store_id = \"YOUR_DATA_STORE_ID\"\n",
    "\n",
    "# Must specify either `gcs_uri` or (`bigquery_dataset` and `bigquery_table`)\n",
    "# Format: `gs://bucket/directory/object.json` or `gs://bucket/directory/*.json`\n",
    "# gcs_uri = \"YOUR_GCS_PATH\"\n",
    "# bigquery_dataset = \"YOUR_BIGQUERY_DATASET\"\n",
    "# bigquery_table = \"YOUR_BIGQUERY_TABLE\"\n",
    "\n",
    "GCP_PROJECT= PROJECT_ID=project_id='my-project-0004-346516'\n",
    "LOCATION = location = \"global\"\n",
    "# FILE_PATH =file_path =  \"Winnie_the_Pooh_3_Pages.pdf\"\n",
    "data_store_id = \"\"\n",
    "\n",
    "# Refer to https://cloud.google.com/document-ai/docs/file-types # for supported file types\n",
    "MIME_TYPE =mime_type = \"application/pdf\"\n",
    "\n",
    "gcs_uri = \"gs://my-project-0004-346516/matchingengine/books/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a20fd3ef-f378-4c5b-9010-cb704d0c4f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import discoveryengine\n",
    "\n",
    "from google.cloud import discoveryengine_v1alpha as discoveryengine\n",
    "from google.api_core.client_options import ClientOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff428d9-a159-415c-99c3-b8a85aebc7df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./books/Book1_HarryPotter_and_the_Sorcerers_Stone_pg15.pdf [Content-Type=application/pdf]...\n",
      "Copying file://./books/Book1_The_Sorcerers_Stone.pdf [Content-Type=application/pdf]...\n",
      "Copying file://./books/Book2_The_Chamber_of_Secrets.pdf [Content-Type=application/pdf]...\n",
      "Copying file://./books/Book3_The_Prisoner_of_Azkaban.pdf [Content-Type=application/pdf]...\n",
      "- [4 files][  4.0 MiB/  4.0 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://./books/Book4_The_Goblet_of_Fire.pdf [Content-Type=application/pdf]...\n",
      "Copying file://./books/Book5_The_Order_of_the_Phoenix.pdf [Content-Type=application/pdf]...\n",
      "Copying file://./books/Book6_The_HalfBlood_Prince.pdf [Content-Type=application/pdf]...\n",
      "Copying file://./books/Book7_The_Deathly_Hallows.pdf [Content-Type=application/pdf]...\n",
      "\\ [8 files][ 17.9 MiB/ 17.9 MiB]                                                \n",
      "Operation completed over 8 objects/17.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r ./books/* 'gs://my-project-0004-346516/matchingengine/books/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7157d0d3-af2f-4d57-9f32-de1ad57e7ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://my-project-0004-346516/matchingengine/books/\n",
      "gs://my-project-0004-346516/matchingengine/books/Book1_HarryPotter_and_the_Sorcerers_Stone_pg15.pdf\n",
      "gs://my-project-0004-346516/matchingengine/books/Book1_The_Sorcerers_Stone.pdf\n",
      "gs://my-project-0004-346516/matchingengine/books/Book2_The_Chamber_of_Secrets.pdf\n",
      "gs://my-project-0004-346516/matchingengine/books/Book3_The_Prisoner_of_Azkaban.pdf\n",
      "gs://my-project-0004-346516/matchingengine/books/Book4_The_Goblet_of_Fire.pdf\n",
      "gs://my-project-0004-346516/matchingengine/books/Book5_The_Order_of_the_Phoenix.pdf\n",
      "gs://my-project-0004-346516/matchingengine/books/Book6_The_HalfBlood_Prince.pdf\n",
      "gs://my-project-0004-346516/matchingengine/books/Book7_The_Deathly_Hallows.pdf\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls 'gs://my-project-0004-346516/matchingengine/books/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381af6e-30b4-4323-924f-94228287794a",
   "metadata": {},
   "source": [
    "### Setup Gemini Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aa77d52-b4dd-4402-a7aa-ec1bf0b00afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-cloud-aiplatform\n",
    "GCP_PROJECT= PROJECT_ID=project_id='my-project-0004-346516'\n",
    "LOCATION = REGION = 'us-central1'\n",
    "import os\n",
    "\n",
    "# import streamlit as st\n",
    "import vertexai\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "\n",
    "# @st.cache_resource\n",
    "def get_model():\n",
    "    generation_model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "    return generation_model\n",
    "\n",
    "\n",
    "def get_text_generation(prompt=\"\", **parameters):\n",
    "    generation_model = get_model()\n",
    "    response = generation_model.predict(prompt=prompt, **parameters)\n",
    "\n",
    "    return response.text\n",
    "\n",
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "parameters = {\n",
    "    \"candidate_count\": 1,\n",
    "    \"max_output_tokens\": 1024,\n",
    "    \"temperature\": 1,\n",
    "    \"top_k\": 40\n",
    "}\n",
    "\n",
    "def generate_palm_unicorn_v1(input_prompt):\n",
    "    \n",
    "    model = TextGenerationModel.from_pretrained(\"text-unicorn@001\")\n",
    "\n",
    "    response = model.predict(\n",
    "        input_prompt,\n",
    "        **parameters\n",
    "    )\n",
    "    print(f\"Response from Model: {response.text}\")\n",
    "    \n",
    "    return(response.text)\n",
    "\n",
    "def generate_palm_bison32k(input_prompt):\n",
    "    \n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison-32k\")\n",
    "\n",
    "    response = model.predict(\n",
    "        input_prompt,\n",
    "        **parameters\n",
    "    )\n",
    "    print(f\"Response from Model: {response.text}\")\n",
    "    \n",
    "    return(response.text)\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "\n",
    "# input_prompt = \"\"\"can you give me details of paracetamol\"\"\"\n",
    "\n",
    "def generate(input_prompt):\n",
    "    model = GenerativeModel(\"gemini-ultra\")\n",
    "    responses = model.generate_content(\n",
    "        input_prompt ,\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 2048,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 1,\n",
    "        \"top_k\": 32\n",
    "    },\n",
    "        safety_settings=[],\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    all_response  = []\n",
    "    \n",
    "    for response in responses:\n",
    "        # print(response.text, end=\"\")\n",
    "        all_response.append(response.text)\n",
    "    \n",
    "    # print (all_response)\n",
    "    \n",
    "    return(\" \".join(all_response))\n",
    "    \n",
    "\n",
    "def generate_pro(input_prompt):\n",
    "    model = GenerativeModel(\"gemini-pro\")\n",
    "    responses = model.generate_content(\n",
    "    input_prompt,\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 2048,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 1\n",
    "    },stream=True,)\n",
    "    \n",
    "    all_response  = []\n",
    "    \n",
    "    for response in responses:\n",
    "        all_response.append(response.text)\n",
    "    \n",
    "    # print (all_response)\n",
    "    \n",
    "    return(\" \".join(all_response))\n",
    "\n",
    "\n",
    "\n",
    "from langchain_google_vertexai import VertexAI as langchainVertexAI\n",
    "\n",
    "def generate_langchain_pro(input_prompt):\n",
    "    model = langchainVertexAI(model_name=\"gemini-pro\")\n",
    "\n",
    "    all_response = model.invoke(input_prompt)\n",
    "\n",
    "    # print (all_response)\n",
    "    \n",
    "    return(all_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3d15d-8a38-483c-8938-421ddcae4e8b",
   "metadata": {},
   "source": [
    "### Create an empty datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69facd95-3cb7-436f-9c5c-e4d790f37ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data_store(\n",
    "    project_id: str, location: str, data_store_name: str, data_store_id: str\n",
    "):\n",
    "    # Create a client\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if location != \"global\"\n",
    "        else None\n",
    "    )\n",
    "    client = discoveryengine.DataStoreServiceClient(client_options=client_options)\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    data_store = discoveryengine.DataStore(\n",
    "        display_name=data_store_name,\n",
    "        industry_vertical=\"GENERIC\",\n",
    "        content_config=\"CONTENT_REQUIRED\",\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateDataStoreRequest(\n",
    "        parent=discoveryengine.DataStoreServiceClient.collection_path(\n",
    "            project_id, location, \"default_collection\"\n",
    "        ),\n",
    "        data_store=data_store,\n",
    "        data_store_id=data_store_id,\n",
    "    )\n",
    "    operation = client.create_data_store(request=request)\n",
    "\n",
    "    # Make the request\n",
    "    # The try block is necessary to prevent execution from haulting due to an error being thrown when the datastore takes a while to instantiate\n",
    "    try:\n",
    "        response = operation.result(timeout=90)\n",
    "    except:\n",
    "        print(\"long-running operation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6ccca82-4f07-4c3f-983e-3f5a82453cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The datastore name can only contain lowercase letters, numbers, and hyphens\n",
    "DATASTORE_NAME = \"harry-potter-books2\"\n",
    "DATASTORE_ID = f\"{DATASTORE_NAME}-id\"\n",
    "\n",
    "LOCATION = 'global'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6faf37-4045-4fea-8af3-ee749ce54c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data_store(PROJECT_ID, LOCATION, DATASTORE_NAME, DATASTORE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aedff0-46ad-4339-884e-1ae7d8664bbe",
   "metadata": {},
   "source": [
    "### Import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "707b0999-27c8-4a67-99e3-466d0eb582e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_documents(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    gcs_uri: str,\n",
    "):\n",
    "    # Create a client\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if location != \"global\"\n",
    "        else None\n",
    "    )\n",
    "    client = discoveryengine.DocumentServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the search engine branch.\n",
    "    # e.g. projects/{project}/locations/{location}/dataStores/{data_store_id}/branches/{branch}\n",
    "    parent = client.branch_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        branch=\"default_branch\",\n",
    "    )\n",
    "\n",
    "    source_documents = [f\"{gcs_uri}/*\"]\n",
    "\n",
    "    request = discoveryengine.ImportDocumentsRequest(\n",
    "        parent=parent,\n",
    "        gcs_source=discoveryengine.GcsSource(\n",
    "            input_uris=source_documents, data_schema=\"content\"\n",
    "        ),\n",
    "        # Options: `FULL`, `INCREMENTAL`\n",
    "        reconciliation_mode=discoveryengine.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.import_documents(request=request)\n",
    "\n",
    "    response = operation.result()\n",
    "\n",
    "    # Once the operation is complete,\n",
    "    # get information from operation metadata\n",
    "    metadata = discoveryengine.ImportDocumentsMetadata(operation.metadata)\n",
    "\n",
    "    # Handle the response\n",
    "    return operation.operation.name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddcf6570-fb7b-451a-8216-8a8094a98614",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/255766800726/locations/global/collections/default_collection/dataStores/harry-potter-books2-id/branches/0/operations/import-documents-10283921769104426845'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(gcs_uri)\n",
    "\n",
    "source_documents_gs_uri = (\"gs://my-project-0004-346516/matchingengine/books\")\n",
    "\n",
    "import_documents(PROJECT_ID, LOCATION, DATASTORE_ID, source_documents_gs_uri)\n",
    "\n",
    "# import_documents_sample(PROJECT_ID, LOCATION, DATASTORE_ID, source_documents_gs_uri)\n",
    "    \n",
    "# \"gs://my-project-0004-346516/matchingengine/books/Book2_The_Chamber_of_Secrets.pdf\",\n",
    "# \"gs://my-project-0004-346516/matchingengine/books/Book3_The_Prisoner_of_Azkaban.pdf\",\n",
    "# \"gs://my-project-0004-346516/matchingengine/books/Book4_The_Goblet_of_Fire.pdf\",\n",
    "# \"gs://my-project-0004-346516/matchingengine/books/Book5_The_Order_of_the_Phoenix.pdf\",\n",
    "# \"gs://my-project-0004-346516/matchingengine/books/Book6_The_HalfBlood_Prince.pdf\",\n",
    "# \"gs://my-project-0004-346516/matchingengine/books/Book7_The_Deathly_Hallows.pdf\",\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d660a2-22b0-4ebd-b8ff-be6c8519ed74",
   "metadata": {},
   "source": [
    "### Create a Search Engine\n",
    "This is used to set the search_tier to enterprise and to enable advanced LLM features.\n",
    "\n",
    "Enterprise tier is required to get extractive answers from a search query and advanced LLM features are required to sumarize search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4981ad32-c5d4-43e8-b0c5-1cee6540504a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_engine(\n",
    "    project_id: str, location: str, data_store_name: str, data_store_id: str\n",
    "):\n",
    "    # Create a client\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if location != \"global\"\n",
    "        else None\n",
    "    )\n",
    "    client = discoveryengine.EngineServiceClient(client_options=client_options)\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    config = discoveryengine.Engine.SearchEngineConfig(\n",
    "        search_tier=\"SEARCH_TIER_ENTERPRISE\", search_add_ons=[\"SEARCH_ADD_ON_LLM\"]\n",
    "    )\n",
    "\n",
    "    engine = discoveryengine.Engine(\n",
    "        display_name=data_store_name,\n",
    "        solution_type=\"SOLUTION_TYPE_SEARCH\",\n",
    "        industry_vertical=\"GENERIC\",\n",
    "        data_store_ids=[data_store_id],\n",
    "        search_engine_config=config,\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateEngineRequest(\n",
    "        parent=discoveryengine.DataStoreServiceClient.collection_path(\n",
    "            project_id, location, \"default_collection\"\n",
    "        ),\n",
    "        engine=engine,\n",
    "        engine_id=engine.display_name,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.create_engine(request=request)\n",
    "    response = operation.result(timeout=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2487d037-9b14-4c2f-865f-4c42a3b16a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_engine(PROJECT_ID, LOCATION, DATASTORE_NAME, DATASTORE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f813ed03-5f9b-4386-ac26-03e6022c2a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Please use the link to create the below command #\n",
    "# https://cloud.google.com/generative-ai-app-builder/docs/create-engine-es#genappbuilder_create_app-drest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef86cff3-881b-4f8f-aaed-e1dd4386afae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !curl -X POST \\\n",
    "# -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "# -H \"Content-Type: application/json\" \\\n",
    "# -H \"X-Goog-User-Project: my-project-0004-346516\" \\\n",
    "# \"https://discoveryengine.googleapis.com/v1/projects/my-project-0004-346516/locations/global/collections/default_collection/engines?engineId=harry-potter-books2-id\" \\\n",
    "# -d '{ \"displayName\": \"harrp_potter_books2\",  \"dataStoreIds\": [\"harry-potter-books2-id\"],   \"solutionType\": \"SOLUTION_TYPE_SEARCH\",  \"searchEngineConfig\": {     \"searchTier\": \"SEARCH_TIER_ENTERPRISE\",     \"searchAddOns\": [\"SEARCH_ADD_ON_LLM\"] } }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d9dad-5758-4447-925a-5fc59d3cb520",
   "metadata": {},
   "source": [
    "### Query your Datastore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee26540f-72d3-418c-954e-859cdb54bb3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def search_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    search_query: str,\n",
    ") -> List[discoveryengine.SearchResponse]:\n",
    "    #  For more information, refer to:\n",
    "    # https://cloud.google.com/generative-ai-app-builder/docs/locations#specify_a_multi-region_for_your_data_store\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if LOCATION != \"global\"\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # Create a client\n",
    "    client = discoveryengine.SearchServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the search engine serving config\n",
    "    # e.g. projects/{project_id}/locations/{location}/dataStores/{data_store_id}/servingConfigs/{serving_config_id}\n",
    "    serving_config = client.serving_config_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        serving_config=\"default_config\",\n",
    "    )\n",
    "\n",
    "    # Optional: Configuration options for search\n",
    "    # Refer to the `ContentSearchSpec` reference for all supported fields:\n",
    "    # https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.types.SearchRequest.ContentSearchSpec\n",
    "    content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(\n",
    "        # For information about snippets, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/snippets\n",
    "        snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(\n",
    "            return_snippet=True\n",
    "        ),\n",
    "        # For information about search summaries, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/get-search-summaries\n",
    "        summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(\n",
    "            summary_result_count=5,\n",
    "            include_citations=True,\n",
    "            ignore_adversarial_query=True,\n",
    "            ignore_non_summary_seeking_query=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Refer to the `SearchRequest` reference for all supported fields:\n",
    "    # https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.types.SearchRequest\n",
    "    request = discoveryengine.SearchRequest(\n",
    "        serving_config=serving_config,\n",
    "        query=search_query,\n",
    "        page_size=10,\n",
    "        content_search_spec=content_search_spec,\n",
    "        query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(\n",
    "            condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,\n",
    "        ),\n",
    "        spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(\n",
    "            mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    response = client.search(request)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df8ba78c-a51a-4349-b07a-66ff0f4ca81a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ron Weasley and Hermione Granger are Harry Potter's best friends at Hogwarts [1, 2].\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the best friend of harry potter?\"\n",
    "\n",
    "print(search_sample(PROJECT_ID, LOCATION, DATASTORE_ID, query).summary.summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820d9d3-5267-4107-be49-055ce53e84b1",
   "metadata": {},
   "source": [
    "### Code to Run through all the Q&A and RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b094b11b-edeb-4f83-9858-764f178a29f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ron Weasley'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gemini_query\n",
    "generate_pro(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093465c-64b5-4202-b311-75db280e6e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration # 0\n",
      "What is the name of the magical creature that can only be seen by those who have witnessed death? \n",
      "Response from Model:  Nearly Headless Nick\n",
      "iteration # 1\n",
      "What is the name of the school newspaper at Hogwarts? \n",
      "Response from Model:  The name of the school newspaper at Hogwarts is the Daily Prophet.\n",
      "iteration # 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "filename = \"./harry_potte_qa_output.csv\"\n",
    "df_qa_VertexSearch = pd.read_csv(filename, sep =\"|\")\n",
    "\n",
    "System_Prompts = \"\"\" You are an expert in reading harry potter books, but only provide evidences from the information provide and do not use an other information\n",
    "so here are some search results : \n",
    "\"\"\"\n",
    "\n",
    "Question_Prompts = \"\"\" -- Based on information above help to answer following user question\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for i in range(0, len(df_qa_VertexSearch)):\n",
    "    \n",
    "    print(\"iteration #\", i)\n",
    "    time.sleep(2)  \n",
    "    \n",
    "    RAG_query = df_qa_VertexSearch.loc[i,'Question'] \n",
    "    \n",
    "    print(RAG_query)\n",
    "    RAG_results = search_sample(PROJECT_ID, LOCATION, DATASTORE_ID, RAG_query).summary.summary_text\n",
    "    \n",
    "    Gemini_query = System_Prompts + \" \" + RAG_results + \" \" + Question_Prompts + \" \" + df_qa_VertexSearch.loc[i,'Question']\n",
    "    \n",
    "    try:        \n",
    "        df_qa_VertexSearch.loc[i, \"Gemini_pro_model_output_v1\"] = generate_pro(Gemini_query)\n",
    "        df_qa_VertexSearch.loc[i, \"palm_bison32k_output_v1\"] = generate_palm_bison32k(Gemini_query)\n",
    "\n",
    "    except:\n",
    "        df_qa_VertexSearch.loc[i, \"Gemini_pro_model_output_v1\"] = \"No answer found\"\n",
    "        df_qa_VertexSearch.loc[i, \"palm_bison32k_output_v1\"] = \"No answer found\"\n",
    "        print(\"long-running operation\")\n",
    "\n",
    "\n",
    "\n",
    "output1 = \"./harry_potter_qa_model_RAG_VertexSearch.csv\"\n",
    "\n",
    "df_qa_VertexSearch.to_csv(output1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c7dc8-ecbc-4ed9-ad15-7c67011aab79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_qa_VertexSearch.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f4119-fe9f-4742-9c78-29097f20b91f",
   "metadata": {},
   "source": [
    "## Generating factual question about the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7106e86-00af-44ca-9bea-8d970a70d5f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import vertexai\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "Region = \"us-central1\"\n",
    "GCP_PROJECT= PROJECT_ID=project_id='my-project-0004-346516'\n",
    "\n",
    "vertexai.init()\n",
    "\n",
    "def generate_pro(input_prompt):\n",
    "    model = GenerativeModel(\"gemini-pro\")\n",
    "    responses = model.generate_content(\n",
    "    input_prompt,\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 2048,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 1\n",
    "    },stream=True,)\n",
    "    \n",
    "    all_response  = []\n",
    "    \n",
    "    for response in responses:\n",
    "        all_response.append(response.text)\n",
    "    \n",
    "    # print (all_response)\n",
    "    \n",
    "    return(\" \".join(all_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22abc1e-1ee6-440a-ab7c-acc7d01c6512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import ImageGenerationModel\n",
    "\n",
    "imagen_model = ImageGenerationModel.from_pretrained(\"imagegeneration@005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592fd6e-bc43-451b-abce-a7bd20ed00db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prev_question = \"\"\n",
    "new_topic = \"\"\n",
    "LOCATION='global'\n",
    "\n",
    "for i in range(0,20):\n",
    "\n",
    "    query = \"Generate a question based on the facts from the search \"\n",
    "    \n",
    "    full_query = query + \"  do not generate repeated questions /n \\n  but you may choose this topic here :: \" + str(new_topic)\n",
    "    \n",
    "    question = search_sample(PROJECT_ID, LOCATION, DATASTORE_ID, full_query).summary.summary_text\n",
    "    print(question)\n",
    "    \n",
    "    if prev_question == question :\n",
    "        input_prompt = \" do not generate topic related to this :: -- \" + new_topic  + \\\n",
    "        \"   give me a two or three word topic about happy potter \"\n",
    "        new_topic = generate_pro(input_prompt)\n",
    "        print(\"new_topic\", new_topic)\n",
    "    \n",
    "    if prev_question != question :\n",
    "        # input_question = \"What is a quote from Harry Potter and the Sorcerer's Stone\"\n",
    "        system_prompt = \" Convert this question to a meaning prompt for imagen model to create a good image\"\n",
    "\n",
    "        prompt = question + \" \" + system_prompt\n",
    "        image_prompt = generate_pro(prompt)\n",
    "\n",
    "        \n",
    "        try:\n",
    "            # Code that may break\n",
    "            response = imagen_model.generate_images( prompt=image_prompt,)\n",
    "            response.images[0].show()\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Handle the exception\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"skipping to next question - no image for this\")\n",
    "\n",
    "    prev_question = question\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
